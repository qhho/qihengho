---
title: Recursively-Constrained Partially Observable Markov Decision Processes
publication_types:
  - "1"
authors:
  - Qi Heng Ho
  - Tyler Becker
  - Ben Kraske
  - Zakariya Laouar
  - Martin Feather
  - Federico Rossi
  - Morteza Lahijanian
  - Zachary Sunberg
doi: https://doi.org/10.48550/arXiv.2310.09688
publication: Uncertainty in Artificial Intelligence (Oral)
abstract: "Many sequential decision problems involve optimizing one objective
  function while imposing constraints on other objectives. Constrained Partially
  Observable Markov Decision Processes (C-POMDP) model this case with transition
  uncertainty and partial observability. In this work, we first show that
  C-POMDPs violate the optimal substructure property over successive decision
  steps and thus may exhibit behaviors that are undesirable for some (e.g.,
  safety critical) applications. Additionally, online re-planning in C-POMDPs is
  often ineffective due to the inconsistency resulting from this violation. To
  address these drawbacks, we introduce the Recursively-Constrained POMDP
  (RC-POMDP), which imposes additional history-dependent cost constraints on the
  C-POMDP. We show that, unlike C-POMDPs, RC-POMDPs always have deterministic
  optimal policies and that optimal policies obey Bellman's principle of
  optimality. We also present a point-based dynamic programming algorithm for
  RC-POMDPs. Evaluations on benchmark problems demonstrate the efficacy of our
  algorithm and show that policies for RC-POMDPs produce more desirable
  behaviors than policies for C-POMDPs. "
draft: false
featured: false
image:
  filename: featured
  focal_point: Smart
  preview_only: false
date: 2024-11-06T03:01:02.225Z
---
